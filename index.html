<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Paper Title Here</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link href="https://fonts.googleapis.com/css2?family=Merriweather&display=swap" rel="stylesheet" />
  <link rel="stylesheet" href="style.css" />
  <script src="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/js/all.min.js" crossorigin="anonymous"></script>
</head>
<body>
  <!-- Navbar -->
  <nav class="navbar">
    <a href="#abstract">Abstract</a>
    <a href="#figures">Figures</a>
    <a href="#code">Code & Data</a>
  </nav>

  <!-- Main Content -->
  <div class="container">
    <h1>Paper Title Here</h1>
    <p class="anonymous-note"><em>Anonymous submission – version 1</em></p>
    <p>
      <a id="code" href="#">
        <i class="fa-brands fa-github github-icon"></i>
        View Code and Data
      </a>
    </p>

    <hr class="section-divider" />

    <!-- Abstract -->
    <h2 id="abstract">Abstract Title</h2>
    <p class="section-text">Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed non risus. Suspendisse lectus tortor, dignissim sit amet.</p>

    <hr class="section-divider" />

    <!-- Figures -->
    <h2 id="figures">Figures</h2>
    <div class="controls">
      <label for="figureSelect">Choose a figure:</label>
      <select id="figureSelect">
        <option value="fig1">Figure 1</option>
        <option value="fig2">Figure 2</option>
        <option value="fig3">Figure 3</option>
        <option value="fig4">Figure 4</option>
        <option value="fig5">Figure 5</option>
      </select>
      <button id="showBtn">Show Figure</button>
    </div>

    <div class="figure-container">
      <embed id="figureDisplay" src="figures/meta_plot_swapped_axes_top_acc.pdf" type="application/pdf" width="100%" height="500px" />
    </div>

    <div class="figure-descriptions">
      <p class="figure-text" id="fig1-text">
        <strong>Figure 1:</strong><br>
        <strong>(A)</strong> Model recovery accuracy across different dataset sizes.<br>
        <strong>(B, C, D)</strong> Confusion matrices at three training set sizes.<br>
        Each matrix row corresponds to the data-generating model, and each column to the recovered model.<br>
        Diagonal entries represent correct model recovery.
      </p>
      <p class="figure-text" id="fig2-text">
        <strong>Figure 2:</strong><br>
        Model test accuracy on the THINGS odd-one-out dataset over gradient levels of linear-probing flexibility.<br>
        <strong>(A)</strong> Zero-shot evaluation.<br>
        <strong>(B)</strong> Diagonal transformation matrix.<br>
        <strong>(C)</strong> Rectangular transformation (p×10).<br>
        <strong>(D)</strong> Square transformation (p×p).<br>
        OpenAI CLIP ResNet-50 yields the highest predictive accuracy.
      </p>
      <p class="figure-text" id="fig3-text">
        <strong>Figure 3:</strong><br>
        <strong>(A)</strong> Mean rank of the data-generating model.<br>
        <strong>(B)</strong> Mean rank when model is <em>not</em> the data generator.
      </p>
      <p class="figure-text" id="fig4-text">
        <strong>Figure 4:</strong><br>
        Model recovery accuracy vs. best-case predictive accuracy.<br>
        Each point reflects a probe flexibility and training size.
      </p>
      <p class="figure-text" id="fig5-text">
        <strong>Figure 5:</strong><br>
        Change in representational dissimilarity after linear transformation.<br>
        MDS: red dot = original; green arrow = shift.<br>
        VICE model used as reference.
      </p>
    </div>

    <hr class="section-divider" />

    <footer class="footer">
      <p>This project was created with ❤️ for anonymous academic review.</p>
    </footer>
  </div>

  <script src="script.js"></script>
</body>
</html>
